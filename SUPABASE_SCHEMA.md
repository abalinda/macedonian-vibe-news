# Supabase `posts` Table Schema

Updated documentation for the posts table including the new `scraped_at` timestamp column.

## Table Structure

| Column | Type | Description | Notes |
|--------|------|-------------|-------|
| `id` | int | Primary key | Auto-generated |
| `title` | text | Article headline | From RSS feed |
| `link` | text | Article URL | Unique constraint |
| `source` | text | RSS feed source | e.g., "IT.mk", "Porta3" |
| `category` | text | Article category | Tech, Culture, Lifestyle, Business |
| `teaser` | text | AI-generated short snippet | Max 120 chars, uppercase |
| `summary` | text | Full article summary | Generated by Gemini AI |
| `image_url` | text | Featured image URL | Scraped from article |
| `featured` | boolean | Is featured story | Used for homepage rotation |
| `published_at` | timestamp | Article publication date | From RSS feed |
| `scraped_at` | timestamp | When article was scraped | **NEW** - UTC timestamp |
| `created_at` | timestamp | When record created | Auto-generated by Supabase |
| `updated_at` | timestamp | Last update timestamp | Auto-managed by Supabase |

## New Column: `scraped_at`

**Purpose:** Track when each article was scraped from RSS feeds

**Type:** `timestamp with time zone` (PostgreSQL)

**Format:** ISO 8601 with UTC timezone (e.g., `2025-12-01T22:30:45Z`)

**Set By:** Scraper at the start of each batch processing run

**Use Cases:**
- Track scraper run time for debugging
- Filter articles by scrape date (e.g., "articles scraped in last 24 hours")
- Monitor data freshness
- Identify scraper execution patterns

## SQL Column Definition

If adding manually to existing database:

```sql
ALTER TABLE posts
ADD COLUMN scraped_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP;

-- Create index for performance (optional, if doing many queries by scraped_at)
CREATE INDEX idx_posts_scraped_at ON posts(scraped_at DESC);
```

## Python Implementation

The scraper now includes:

```python
# Add scraped_at timestamp to all articles
scraped_at = datetime.utcnow().isoformat() + "Z"
for article in curated_articles:
    article["scraped_at"] = scraped_at
```

All articles in a single scraper run receive the same timestamp, indicating they were scraped together.

## Example Data

```json
{
  "id": 1,
  "title": "New Tech Innovation in Macedonia",
  "link": "https://it.mk/news/123",
  "source": "IT.mk",
  "category": "Tech",
  "teaser": "REVOLUTIONARY NEW AI TECHNOLOGY UNVEILED",
  "summary": "Local tech company announces groundbreaking AI research...",
  "image_url": "https://example.com/image.jpg",
  "featured": false,
  "published_at": "2025-12-01T14:30:00Z",
  "scraped_at": "2025-12-01T22:15:30Z",
  "created_at": "2025-12-01T22:15:31Z",
  "updated_at": "2025-12-01T22:15:31Z"
}
```

## Queries

### Get articles scraped today
```sql
SELECT title, source, scraped_at
FROM posts
WHERE scraped_at::date = CURRENT_DATE
ORDER BY scraped_at DESC;
```

### Get articles scraped in last 4 hours
```sql
SELECT title, source, scraped_at
FROM posts
WHERE scraped_at > NOW() - INTERVAL '4 hours'
ORDER BY scraped_at DESC;
```

### Count articles per scraper run
```sql
SELECT scraped_at, COUNT(*) as article_count, COUNT(DISTINCT source) as source_count
FROM posts
GROUP BY scraped_at
ORDER BY scraped_at DESC
LIMIT 10;
```

### Find stale articles (not updated in 48 hours)
```sql
SELECT title, source, scraped_at
FROM posts
WHERE scraped_at < NOW() - INTERVAL '48 hours'
ORDER BY scraped_at DESC;
```

## Monitoring

### Check Scraper Execution Logs

The scraper logs include `scraped_at` in upsert events:

```json
{
  "event_type": "supabase_upsert",
  "source": "IT.mk",
  "count": 8,
  "scraped_at": "2025-12-01T22:15:30Z"
}
```

View logs:
```bash
tail -f scraper/logs/scraper_log.jsonl | grep supabase_upsert
```

## Notes

- The timestamp is set **at the start** of processing each RSS feed
- All articles from the same scraper run have **identical** `scraped_at` values
- Different feeds in the same run may have slightly different timestamps if you add per-feed timing
- Useful for identifying which scraper run an article came from
